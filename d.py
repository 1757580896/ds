import asyncio
import aiohttp
import re
from urllib.parse import urlparse
from collections import defaultdict

# åŸå§‹URLåˆ—è¡¨ï¼ˆæ­¤å¤„å·²ç¼©çŸ­ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºå®Œæ•´åˆ—è¡¨ï¼‰
urls = [
    "http://example1.com:9901",
    "http://example2.com:9901",
]

async def generate_modified_urls(original_url):
    """ç”Ÿæˆä¿®æ”¹åçš„IPåœ°å€åºåˆ—"""
    parsed = urlparse(original_url)
    base_ip = '.'.join(parsed.hostname.split('.')[:-1])
    return [
      f"{parsed.scheme}://{base_ip}.{i}:{parsed.port}/iptv/live/1000.json?key=txiptv"
        for i in range(1, 256)
    ]

async def check_node(session, url, semaphore):
    """å¼‚æ­¥æ£€æŸ¥èŠ‚ç‚¹å¯ç”¨æ€§"""
    async with semaphore:
        try:
            async with session.get(url, timeout=2) as response:
                if response.status == 200:
                    print(f"âœ… Valid node: {url}")
                    return url
        except Exception as e:
            return None

async def fetch_channels(session, node_url, semaphore):
  """è·å–é¢‘é“åˆ—è¡¨"""
    async with semaphore:
        try:
            async with session.get(node_url, timeout=2) as response:
                data = await response.json()
                base_url = f"{urlparse(node_url).scheme}://{urlparse(node_url).hostname}:{urlparse(node_url).port}"
                
                channels = []
                for item in data.get('data', []):
                  name = re.sub(r'\s+', '', item.get('name', ''))
                    stream_url = item.get('url', '')
                    
                    # æ ‡å‡†åŒ–å¤„ç†
                    name = re.sub(r'CCTV(\d+)å°', r'CCTV\1', name)
                    name = re.sub(r'é«˜æ¸…|æ ‡æ¸…|è¶…æ¸…|HD', '', name)
                    
                    if not stream_url.startswith('http'):
                        stream_url = f"{base_url}{stream_url}"
                    
                    channels.append((name, stream_url))
                  return channels
        except Exception as e:
            return []

async def speed_test(session, channel_name, channel_url, semaphore):
    """å¼‚æ­¥æµ‹é€Ÿ"""
    async with semaphore:
        try:
            # è·å–m3u8å†…å®¹
            async with session.get(channel_url, timeout=5) as response:
                if response.status != 200:
                  return None
                
                m3u8_text = await response.text()
                ts_list = [line for line in m3u8_text.split('\n') 
                          if line.strip() and not line.startswith('#')]
                
                if not ts_list:
                    return None
                
                # æµ‹è¯•ç¬¬ä¸€ä¸ªç‰‡æ®µ
                ts_url = f"{channel_url.rsplit('/', 1)[0]}/{ts_list[0]}"
                start_time = asyncio.get_event_loop().time()
              async with session.get(ts_url, timeout=5) as ts_response:
                    content = await ts_response.read()
                    elapsed = asyncio.get_event_loop().time() - start_time
                
                speed = len(content) / elapsed / 1024  # KB/s
                return (channel_name, channel_url, speed)
                
        except Exception as e:
            return None

async def main():
  # åˆå§‹åŒ–è¿æ¥æ± 
    connector = aiohttp.TCPConnector(limit=0)  # ä¸é™åˆ¶è¿æ¥æ•°
    async with aiohttp.ClientSession(connector=connector) as session:
        # é˜¶æ®µ1ï¼šå‘ç°æœ‰æ•ˆèŠ‚ç‚¹
        print("ğŸš€ Starting node discovery...")
        discovery_sem = asyncio.Semaphore(100)
        all_urls = []
        for url in urls:
            all_urls.extend(await generate_modified_urls(url))
        
        nodes = await asyncio.gather(*[
            check_node(session, url, discovery_sem) 
      for url in all_urls
        ])
        valid_nodes = [n for n in nodes if n]
        print(f"ğŸ¯ Found {len(valid_nodes)} valid nodes")
        
        # é˜¶æ®µ2ï¼šæ”¶é›†é¢‘é“
        print("ğŸ“¡ Fetching channels...")
        fetch_sem = asyncio.Semaphore(50)
        channels = await asyncio.gather(*[
            fetch_channels(session, node, fetch_sem) 
      for node in valid_nodes
        ])
        all_channels = [c for sublist in channels for c in sublist if sublist]
        print(f"ğŸ“º Total channels found: {len(all_channels)}")
        
        # é˜¶æ®µ3ï¼šæµ‹é€Ÿç­›é€‰
        print("â±ï¸ Speed testing...")
        speed_sem = asyncio.Semaphore(20)
        results = await asyncio.gather(*[
            speed_test(session, name, url, speed_sem)
            for name, url in all_channels
        ])
        valid_channels = [r for r in results if r]
      # åˆ†ç±»æ•´ç†
        category = defaultdict(list)
        for name, url, speed in valid_channels:
            if speed < 500:  # è¿‡æ»¤ä½é€Ÿæº
                continue
            key = 'CCTV' if 'CCTV' in name else ('å«è§†' if 'å«è§†' in name else 'å…¶ä»–')
            category[key].append((name, url, speed))
        
        # æ’åºå»é‡ï¼ˆæ¯ä¸ªé¢‘é“ä¿ç•™æœ€å¿«8ä¸ªï¼‰
        final = defaultdict(list)
        for key, items in category.items():
            groups = defaultdict(list)
            for name, url, speed in items:
                groups[name].append((speed, url))
              
            for name, candidates in groups.items():
                sorted_candidates = sorted(candidates, reverse=True)[:8]
                final[key].extend([
                    (name, url) for _, url in sorted_candidates
                ])
              
        # ç”Ÿæˆç»“æœæ–‡ä»¶
        with open("itvlist.txt", "w", encoding="utf-8") as f:
            for cat in ['CCTV', 'å«è§†', 'å…¶ä»–']:
                f.write(f"{cat}é¢‘é“,#genre#\n")
                for name, url in final.get(cat, []):
                    f.write(f"{name},{url}\n")
                f.write("\n")
        print("ğŸ‰ Done! Results saved to itvlist.txt")
      
if __name__ == "__main__":
    asyncio.run(main())
      
      
